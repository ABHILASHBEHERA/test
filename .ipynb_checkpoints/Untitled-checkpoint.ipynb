{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk:\n",
      "\n",
      "NAME\n",
      "    nltk\n",
      "\n",
      "DESCRIPTION\n",
      "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
      "    for Natural Language Processing.  A free online book is available.\n",
      "    (If you use the library for academic research, please cite the book.)\n",
      "    \n",
      "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
      "    http://nltk.org/book\n",
      "    \n",
      "    @version: 3.5\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    app (package)\n",
      "    book\n",
      "    ccg (package)\n",
      "    chat (package)\n",
      "    chunk (package)\n",
      "    classify (package)\n",
      "    cli\n",
      "    cluster (package)\n",
      "    collections\n",
      "    collocations\n",
      "    compat\n",
      "    corpus (package)\n",
      "    data\n",
      "    decorators\n",
      "    downloader\n",
      "    draw (package)\n",
      "    featstruct\n",
      "    grammar\n",
      "    help\n",
      "    inference (package)\n",
      "    internals\n",
      "    jsontags\n",
      "    lazyimport\n",
      "    lm (package)\n",
      "    metrics (package)\n",
      "    misc (package)\n",
      "    parse (package)\n",
      "    probability\n",
      "    sem (package)\n",
      "    sentiment (package)\n",
      "    stem (package)\n",
      "    tag (package)\n",
      "    tbl (package)\n",
      "    test (package)\n",
      "    text\n",
      "    tgrep\n",
      "    tokenize (package)\n",
      "    toolbox\n",
      "    translate (package)\n",
      "    tree\n",
      "    treeprettyprinter\n",
      "    treetransforms\n",
      "    twitter (package)\n",
      "    util\n",
      "    wsd\n",
      "\n",
      "SUBMODULES\n",
      "    agreement\n",
      "    aline\n",
      "    api\n",
      "    association\n",
      "    bleu_score\n",
      "    bllip\n",
      "    boxer\n",
      "    brill\n",
      "    brill_trainer\n",
      "    casual\n",
      "    chart\n",
      "    cistem\n",
      "    confusionmatrix\n",
      "    corenlp\n",
      "    crf\n",
      "    decisiontree\n",
      "    dependencygraph\n",
      "    destructive\n",
      "    discourse\n",
      "    distance\n",
      "    drt\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    glue\n",
      "    hmm\n",
      "    hunpos\n",
      "    ibm1\n",
      "    ibm2\n",
      "    ibm3\n",
      "    ibm4\n",
      "    ibm5\n",
      "    ibm_model\n",
      "    isri\n",
      "    lancaster\n",
      "    lfg\n",
      "    linearlogic\n",
      "    logic\n",
      "    mace\n",
      "    malt\n",
      "    mapping\n",
      "    maxent\n",
      "    megam\n",
      "    meteor_score\n",
      "    mwe\n",
      "    naivebayes\n",
      "    nonprojectivedependencyparser\n",
      "    paice\n",
      "    pchart\n",
      "    perceptron\n",
      "    porter\n",
      "    positivenaivebayes\n",
      "    projectivedependencyparser\n",
      "    prover9\n",
      "    punkt\n",
      "    recursivedescent\n",
      "    regexp\n",
      "    relextract\n",
      "    repp\n",
      "    resolution\n",
      "    ribes_score\n",
      "    rslp\n",
      "    rte_classify\n",
      "    scikitlearn\n",
      "    scores\n",
      "    segmentation\n",
      "    senna\n",
      "    sequential\n",
      "    sexpr\n",
      "    shiftreduce\n",
      "    simple\n",
      "    snowball\n",
      "    sonority_sequencing\n",
      "    spearman\n",
      "    stack_decoder\n",
      "    stanford\n",
      "    stanford_segmenter\n",
      "    tableau\n",
      "    tadm\n",
      "    textcat\n",
      "    texttiling\n",
      "    tnt\n",
      "    toktok\n",
      "    transitionparser\n",
      "    treebank\n",
      "    viterbi\n",
      "    weka\n",
      "    wordnet\n",
      "\n",
      "FUNCTIONS\n",
      "    demo()\n",
      "        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n",
      "    \n",
      "    tee(iterable, n=2, /)\n",
      "        Returns a tuple of n independent iterators.\n",
      "\n",
      "DATA\n",
      "    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n",
      "    SLASH = *slash*\n",
      "    TYPE = *type*\n",
      "    __author_email__ = 'stevenbird1@gmail.com'\n",
      "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
      "    __copyright__ = 'Copyright (C) 2001-2020 NLTK Project.\\n\\nDistribut......\n",
      "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
      "    __license__ = 'Apache License, Version 2.0'\n",
      "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ... p...\n",
      "    __maintainer__ = 'Steven Bird, Edward Loper, Ewan Klein'\n",
      "    __maintainer_email__ = 'stevenbird1@gmail.com'\n",
      "    __url__ = 'http://nltk.org/'\n",
      "    app = <LazyModule 'nltk.nltk.app'>\n",
      "    chat = <LazyModule 'nltk.nltk.chat'>\n",
      "    corpus = <LazyModule 'nltk.nltk.corpus'>\n",
      "    infile = <_io.TextIOWrapper name='C:\\\\Users\\\\Abhilash\\\\an...kages\\\\nlt...\n",
      "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
      "    toolbox = <LazyModule 'nltk.nltk.toolbox'>\n",
      "    version_file = r'C:\\Users\\Abhilash\\anaconda3\\lib\\site-packages\\nltk\\VE...\n",
      "    version_info = sys.version_info(major=3, minor=8, micro=5, releaseleve...\n",
      "\n",
      "VERSION\n",
      "    3.5\n",
      "\n",
      "AUTHOR\n",
      "    Steven Bird, Edward Loper, Ewan Klein\n",
      "\n",
      "FILE\n",
      "    c:\\users\\abhilash\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dot in module numpy:\n",
      "\n",
      "dot(...)\n",
      "    dot(a, b, out=None)\n",
      "    \n",
      "    Dot product of two arrays. Specifically,\n",
      "    \n",
      "    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n",
      "      (without complex conjugation).\n",
      "    \n",
      "    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n",
      "      but using :func:`matmul` or ``a @ b`` is preferred.\n",
      "    \n",
      "    - If either `a` or `b` is 0-D (scalar), it is equivalent to :func:`multiply`\n",
      "      and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.\n",
      "    \n",
      "    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n",
      "      the last axis of `a` and `b`.\n",
      "    \n",
      "    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n",
      "      sum product over the last axis of `a` and the second-to-last axis of `b`::\n",
      "    \n",
      "        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        First argument.\n",
      "    b : array_like\n",
      "        Second argument.\n",
      "    out : ndarray, optional\n",
      "        Output argument. This must have the exact kind that would be returned\n",
      "        if it was not used. In particular, it must have the right type, must be\n",
      "        C-contiguous, and its dtype must be the dtype that would be returned\n",
      "        for `dot(a,b)`. This is a performance feature. Therefore, if these\n",
      "        conditions are not met, an exception is raised, instead of attempting\n",
      "        to be flexible.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n",
      "        scalars or both 1-D arrays then a scalar is returned; otherwise\n",
      "        an array is returned.\n",
      "        If `out` is given, then it is returned.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the last dimension of `a` is not the same size as\n",
      "        the second-to-last dimension of `b`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    vdot : Complex-conjugating dot product.\n",
      "    tensordot : Sum products over arbitrary axes.\n",
      "    einsum : Einstein summation convention.\n",
      "    matmul : '@' operator as method with out parameter.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.dot(3, 4)\n",
      "    12\n",
      "    \n",
      "    Neither argument is complex-conjugated:\n",
      "    \n",
      "    >>> np.dot([2j, 3j], [2j, 3j])\n",
      "    (-13+0j)\n",
      "    \n",
      "    For 2-D arrays it is the matrix product:\n",
      "    \n",
      "    >>> a = [[1, 0], [0, 1]]\n",
      "    >>> b = [[4, 1], [2, 2]]\n",
      "    >>> np.dot(a, b)\n",
      "    array([[4, 1],\n",
      "           [2, 2]])\n",
      "    \n",
      "    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n",
      "    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n",
      "    >>> np.dot(a, b)[2,3,2,1,2,2]\n",
      "    499128\n",
      "    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n",
      "    499128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(numpy.dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
